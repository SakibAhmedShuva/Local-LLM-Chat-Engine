{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3014dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import requests\n",
    "import json\n",
    "import threading\n",
    "import uuid\n",
    "import time # For potential delays or timeouts if needed\n",
    "\n",
    "# Configuration for your Flask API\n",
    "API_BASE_URL = \"http://localhost:5000\" # Adjust if your API is on a different host/port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6109d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching models: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /models (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000173BE95F100>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Helper Function to Get Available Models\n",
    "def get_available_models(api_base_url):\n",
    "    \"\"\"Fetches the list of available models from the API.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{api_base_url}/models\")\n",
    "        response.raise_for_status()  # Raises an exception for HTTP errors\n",
    "        models = response.json()\n",
    "        print(\"Available Models:\")\n",
    "        for model in models:\n",
    "            print(f\"- ID: {model.get('id')}, Name: {model.get('name')}, Type: {model.get('type')}, Source: {model.get('source_type')}\")\n",
    "            if model.get('source_type') == 'local':\n",
    "                print(f\"  Path: {model.get('path')}\")\n",
    "            elif model.get('source_type') == 'hub':\n",
    "                if model.get('type') == 'gguf':\n",
    "                    print(f\"  Repo ID: {model.get('repo_id')}, Filename: {model.get('filename')}\")\n",
    "                else:\n",
    "                    print(f\"  Hub ID/Path: {model.get('path')}\")\n",
    "            # print(f\"  Default Params: {model.get('params')}\") # Uncomment for more detail\n",
    "        return models\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching models: {e}\")\n",
    "        return []\n",
    "\n",
    "# Fetch and display available models when this cell is run\n",
    "AVAILABLE_MODELS = get_available_models(API_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364ceba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Helper Function to Create a New Session\n",
    "def create_new_session(api_base_url):\n",
    "    \"\"\"Creates a new session via the API and returns the session_id.\"\"\"\n",
    "    try:\n",
    "        response = requests.post(f\"{api_base_url}/create-session\")\n",
    "        response.raise_for_status()\n",
    "        session_data = response.json()\n",
    "        if session_data.get('status') == 'success' and session_data.get('session_id'):\n",
    "            print(f\"Created new session: {session_data['session_id']}\")\n",
    "            return session_data['session_id']\n",
    "        else:\n",
    "            print(f\"Failed to create session: {session_data.get('message', 'Unknown error')}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error creating session: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c26371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Helper Function to Ask a Question on a Session (Handles SSE)\n",
    "def ask_question_on_session(api_base_url, model_id, session_id, user_prompt, system_prompt, \n",
    "                            generation_params=None, model_load_params=None, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Sends a question to the chat API for a given session and streams the response.\n",
    "    Returns the complete assistant response.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"session_id\": session_id,\n",
    "        \"prompt\": user_prompt,\n",
    "        \"system_prompt\": system_prompt,\n",
    "        \"model_id\": model_id,\n",
    "        \"temperature\": temperature,  # Base temperature\n",
    "        \"model_specific_params\": generation_params if generation_params else {},\n",
    "        \"model_load_params\": model_load_params if model_load_params else {}\n",
    "    }\n",
    "\n",
    "    full_response_text = \"\"\n",
    "    print(f\"\\n[Session: {session_id}, Model: {model_id}] Asking: {user_prompt[:100]}...\")\n",
    "    if system_prompt:\n",
    "        print(f\"System Prompt: {system_prompt[:100]}...\")\n",
    "\n",
    "    try:\n",
    "        response = requests.post(f\"{api_base_url}/chat\", json=payload, stream=True, timeout=300) # Added timeout\n",
    "        response.raise_for_status()\n",
    "\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                decoded_line = line.decode('utf-8')\n",
    "                if decoded_line.startswith('data: '):\n",
    "                    try:\n",
    "                        data_json_str = decoded_line[len('data: '):]\n",
    "                        data_json = json.loads(data_json_str)\n",
    "                        \n",
    "                        if data_json.get('error'):\n",
    "                            error_msg = f\"[API Error for session {session_id}]: {data_json['error']}\"\n",
    "                            print(error_msg)\n",
    "                            return error_msg # Return error message as response\n",
    "\n",
    "                        if 'text_chunk' in data_json and not data_json.get('is_final'):\n",
    "                            full_response_text += data_json['text_chunk']\n",
    "                            # print(data_json['text_chunk'], end='', flush=True) # For live streaming in notebook\n",
    "                        \n",
    "                        if data_json.get('is_final'):\n",
    "                            if 'full_response' in data_json: # Use server's full response if available\n",
    "                                full_response_text = data_json['full_response']\n",
    "                            # print(\"\\n--- End of Stream ---\")\n",
    "                            break \n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"\\nWarning: Could not decode JSON from stream: {decoded_line}\")\n",
    "        \n",
    "        print(f\"[Session: {session_id}] Full Response: {full_response_text[:100]}...\")\n",
    "        return full_response_text.strip()\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        error_msg = f\"[API Timeout for session {session_id} while asking: {user_prompt[:50]}...]\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"[API Request Error for session {session_id}]: {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd453e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Worker Function to Process a Query Group\n",
    "def worker_process_query_group(query_group_config, model_id, api_base_url, all_results_list, results_lock):\n",
    "    \"\"\"\n",
    "    Worker function for a thread. Processes a group of questions.\n",
    "    Each query_group runs in its own session.\n",
    "    \"\"\"\n",
    "    group_id = query_group_config[\"group_id\"]\n",
    "    print(f\"Thread started for Query Group: {group_id}\")\n",
    "\n",
    "    session_id = create_new_session(api_base_url)\n",
    "    if not session_id:\n",
    "        print(f\"Failed to create session for group {group_id}. Aborting this group.\")\n",
    "        with results_lock:\n",
    "            all_results_list.append({\n",
    "                \"group_id\": group_id,\n",
    "                \"session_id\": None,\n",
    "                \"status\": \"failed_session_creation\",\n",
    "                \"results\": {}\n",
    "            })\n",
    "        return\n",
    "\n",
    "    system_prompt = query_group_config.get(\"system_prompt\", \"\")\n",
    "    generation_params = query_group_config.get(\"generation_params\", {})\n",
    "    model_load_params = query_group_config.get(\"model_load_params\", {})\n",
    "    default_temperature = query_group_config.get(\"temperature\", 0.7) # Can be set per group\n",
    "\n",
    "    group_results_data = {}\n",
    "\n",
    "    # The backend's /chat endpoint handles history accumulation based on session_id.\n",
    "    # We send the system_prompt with each call in this setup, \n",
    "    # or rely on the backend to use the first system_prompt for the session.\n",
    "    # The current backend app.py prepends the system_prompt if provided in the payload.\n",
    "    for q_item in query_group_config[\"questions_and_keys\"]:\n",
    "        user_question = q_item[\"question\"]\n",
    "        answer_key = q_item[\"key\"]\n",
    "        \n",
    "        answer = ask_question_on_session(\n",
    "            api_base_url, \n",
    "            model_id, \n",
    "            session_id, \n",
    "            user_question, \n",
    "            system_prompt, # System prompt is associated with the session by the backend\n",
    "            generation_params,\n",
    "            model_load_params,\n",
    "            temperature=default_temperature\n",
    "        )\n",
    "        group_results_data[answer_key] = answer\n",
    "        # time.sleep(1) # Optional: small delay between questions in the same session if needed\n",
    "\n",
    "    with results_lock:\n",
    "        all_results_list.append({\n",
    "            \"group_id\": group_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"status\": \"completed\",\n",
    "            \"results\": group_results_data\n",
    "        })\n",
    "    print(f\"Thread finished for Query Group: {group_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9000e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "license='''\n",
    "        California\n",
    "        DRIVER LICENSe\n",
    "        dl 11234568\n",
    "        CLASS C\n",
    "        EXP 08/31/2014\n",
    "        END NONE\n",
    "        LNCARDHOLDER FNIMA\n",
    "        2570 24TH STREET ANYTOWN, CA 95818\n",
    "        doB 08/31/1977 RSTR NONE\n",
    "        08311977\n",
    "        VETERAN\n",
    "        Cordhslde\n",
    "        SEX F HGT 5'-05\"\n",
    "        HAIR BRN WGT 125 lb\n",
    "        EYES BRN\n",
    "        DD 00/00/0000NNNAN/ANFD/YY\n",
    "        ISS 08/31/2009\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Main Execution Block\n",
    "\n",
    "# --- Configuration ---\n",
    "# Choose your model ID from the list printed by Cell 2\n",
    "# Example: If you have a local GGUF model named \"mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n",
    "# its ID might be \"gguf_local_mistral-7b-instruct-v0_2_Q4_K_M_gguf\"\n",
    "# Or if you defined a Hub model in online_models.json with id \"zephyr-7b-gguf\"\n",
    "CHOSEN_MODEL_ID = \"gguf_local_Llama-3_2-1B-Instruct-Q8_0\" # <--- !!! SET YOUR MODEL ID HERE !!!\n",
    "# You can also get one from AVAILABLE_MODELS if it's not empty:\n",
    "# if AVAILABLE_MODELS:\n",
    "#    CHOSEN_MODEL_ID = AVAILABLE_MODELS[0]['id'] # Example: use the first available model\n",
    "# else:\n",
    "#    print(\"No models available from API. Please check server and config.\")\n",
    "#    CHOSEN_MODEL_ID = \"default_model_id_placeholder\" # Fallback if no models listed\n",
    "\n",
    "# Define your query groups\n",
    "# Each item in QUERY_GROUPS will be processed in a separate thread, each with a new session.\n",
    "# Questions within a \"questions_and_keys\" list for a single group are asked sequentially *within the same session*.\n",
    "QUERY_GROUPS = [\n",
    "    {\n",
    "        \"group_id\": \"california_license_info_set1\",\n",
    "        \"system_prompt\": (\n",
    "            \"You are an expert AI assistant specializing in California driving licenses. \"\n",
    "            \"Please answer the questions based on the following context. \"\n",
    "            \"Context: The California Department of Motor Vehicles (DMV) states that the minimum age \"\n",
    "            \"to apply for a learner's permit is 15 years and 6 months. Applicants for a REAL ID \"\n",
    "            \"must provide proof of identity, their Social Security number (if eligible), and two \"\n",
    "            \"proofs of California residency. The primary physical address for the CA DMV headquarters \"\n",
    "            \"is in Sacramento, CA, USA. For a standard Class C license, vision screening is required.\"\n",
    "        ),\n",
    "        \"questions_and_keys\": [\n",
    "            {\"question\": \"What is the minimum age to get a learner's permit in California?\", \"key\": \"ca_permit_min_age\"},\n",
    "            {\"question\": \"List the categories of documents needed for a REAL ID application in California.\", \"key\": \"ca_realid_docs\"},\n",
    "            {\"question\": \"What is the city and state of the CA DMV headquarters address?\", \"key\": \"ca_dmv_hq_address\"}\n",
    "        ],\n",
    "        \"temperature\": 0.01, # Override default temperature for this group\n",
    "        \"generation_params\": {\"max_tokens\": 150}, # For GGUF: max_tokens; For HF: max_new_tokens\n",
    "        \"model_load_params\": {\"n_gpu_layers\": -1} # Example for GGUF model\n",
    "        # \"model_load_params\": {\"use_bnb_4bit\": True} # Example for Regular HF model if you want 4-bit\n",
    "    },\n",
    "    {\n",
    "        \"group_id\": \"new_york_license_info_set1\",\n",
    "        \"system_prompt\": (\n",
    "            \"You are an expert AI assistant for New York State driving licenses. \"\n",
    "            \"Context: Standard New York State driver licenses (Class D) are typically valid for 8 years. \"\n",
    "            \"Renewals can often be done online, by mail, or in person at a DMV office. A vision test \"\n",
    "            \"is required for renewal, which can be done at the DMV or by an approved provider.\"\n",
    "        ),\n",
    "        \"questions_and_keys\": [\n",
    "            {\"question\": \"How long is a standard Class D driver's license valid in New York?\", \"key\": \"ny_license_validity\"},\n",
    "            {\"question\": \"Is a vision test mandatory for renewing a NY driver's license?\", \"key\": \"ny_vision_test_renewal\"}\n",
    "        ],\n",
    "        \"temperature\": 0.01,\n",
    "        \"generation_params\": {\"max_tokens\": 100},\n",
    "        # model_load_params can be omitted if defaults are fine or model is already loaded with desired settings\n",
    "    },\n",
    "    {\n",
    "        \"group_id\": \"california_license_info_set2_new_chat\", # Simulates new chat on existing topic\n",
    "        \"system_prompt\": (\n",
    "            \"You are an expert AI assistant specializing in California driving licenses. \"\n",
    "            \"Please answer the questions based on the following context. \"\n",
    "            \"Context: The California Driver Handbook outlines various traffic violations. A first-time \"\n",
    "            \"DUI conviction can result in mandatory Ignition Interlock Device (IID) installation, \"\n",
    "            \"license suspension, fines, and DUI program enrollment. The specific penalties can vary.\"\n",
    "        ),\n",
    "        \"questions_and_keys\": [\n",
    "            {\"question\": \"What are some potential penalties for a first-time DUI in California according to the handbook?\", \"key\": \"ca_dui_penalties_first\"}\n",
    "        ],\n",
    "        \"generation_params\": {\"max_tokens\": 200},\n",
    "        \"model_load_params\": {\"n_gpu_layers\": -1} \n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Execution ---\n",
    "if CHOSEN_MODEL_ID == \"default_model_id_placeholder\" and not AVAILABLE_MODELS:\n",
    "    print(\"CRITICAL: CHOSEN_MODEL_ID is a placeholder and no models were fetched from the API.\")\n",
    "    print(\"Please ensure your Flask server is running, configured with models, and update CHOSEN_MODEL_ID.\")\n",
    "else:\n",
    "    print(f\"Using Model ID: {CHOSEN_MODEL_ID}\")\n",
    "    \n",
    "    collected_results = []\n",
    "    threads = []\n",
    "    results_lock = threading.Lock()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for group_config in QUERY_GROUPS:\n",
    "        thread = threading.Thread(\n",
    "            target=worker_process_query_group,\n",
    "            args=(group_config, CHOSEN_MODEL_ID, API_BASE_URL, collected_results, results_lock)\n",
    "        )\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join() # Wait for all threads to complete\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n--- All threads completed in {end_time - start_time:.2f} seconds ---\")\n",
    "\n",
    "    # --- Display Results ---\n",
    "    print(\"\\n--- Collected Results ---\")\n",
    "    for item in collected_results:\n",
    "        print(f\"\\nQuery Group ID: {item['group_id']}\")\n",
    "        print(f\"Session ID: {item['session_id']}\")\n",
    "        print(f\"Status: {item.get('status', 'N/A')}\")\n",
    "        if item.get(\"results\"):\n",
    "            for key, value in item[\"results\"].items():\n",
    "                print(f\"  '{key}': '{value}'\")\n",
    "        else:\n",
    "            print(\"  No results for this group.\")\n",
    "            \n",
    "    # You can also save `collected_results` to a JSON file\n",
    "    # with open(\"batch_qa_results.json\", \"w\") as f:\n",
    "    #     json.dump(collected_results, f, indent=2)\n",
    "    # print(\"\\nResults saved to batch_qa_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31bcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "31011_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
