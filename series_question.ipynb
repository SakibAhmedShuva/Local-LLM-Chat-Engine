{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3014dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import requests\n",
    "import json\n",
    "import threading\n",
    "import uuid\n",
    "import time # For potential delays or timeouts if needed\n",
    "\n",
    "# Configuration for your Flask API\n",
    "API_BASE_URL = \"http://localhost:5000\" # Adjust if your API is on a different host/port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6109d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching models: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /models (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000173BE95F100>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Helper Function to Get Available Models\n",
    "def get_available_models(api_base_url):\n",
    "    \"\"\"Fetches the list of available models from the API.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{api_base_url}/models\")\n",
    "        response.raise_for_status()  # Raises an exception for HTTP errors\n",
    "        models = response.json()\n",
    "        print(\"Available Models:\")\n",
    "        for model in models:\n",
    "            print(f\"- ID: {model.get('id')}, Name: {model.get('name')}, Type: {model.get('type')}, Source: {model.get('source_type')}\")\n",
    "            if model.get('source_type') == 'local':\n",
    "                print(f\"  Path: {model.get('path')}\")\n",
    "            elif model.get('source_type') == 'hub':\n",
    "                if model.get('type') == 'gguf':\n",
    "                    print(f\"  Repo ID: {model.get('repo_id')}, Filename: {model.get('filename')}\")\n",
    "                else:\n",
    "                    print(f\"  Hub ID/Path: {model.get('path')}\")\n",
    "            # print(f\"  Default Params: {model.get('params')}\") # Uncomment for more detail\n",
    "        return models\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching models: {e}\")\n",
    "        return []\n",
    "\n",
    "# Fetch and display available models when this cell is run\n",
    "AVAILABLE_MODELS = get_available_models(API_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364ceba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Helper Function to Create a New Session\n",
    "def create_new_session(api_base_url):\n",
    "    \"\"\"Creates a new session via the API and returns the session_id.\"\"\"\n",
    "    try:\n",
    "        response = requests.post(f\"{api_base_url}/create-session\")\n",
    "        response.raise_for_status()\n",
    "        session_data = response.json()\n",
    "        if session_data.get('status') == 'success' and session_data.get('session_id'):\n",
    "            print(f\"Created new session: {session_data['session_id']}\")\n",
    "            return session_data['session_id']\n",
    "        else:\n",
    "            print(f\"Failed to create session: {session_data.get('message', 'Unknown error')}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error creating session: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c26371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Helper Function to Ask a Question on a Session (Handles SSE)\n",
    "def ask_question_on_session(api_base_url, model_id, session_id, user_prompt, system_prompt, \n",
    "                            generation_params=None, model_load_params=None, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Sends a question to the chat API for a given session and streams the response.\n",
    "    Returns the complete assistant response.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"session_id\": session_id,\n",
    "        \"prompt\": user_prompt,\n",
    "        \"system_prompt\": system_prompt,\n",
    "        \"model_id\": model_id,\n",
    "        \"temperature\": temperature,  # Base temperature\n",
    "        \"model_specific_params\": generation_params if generation_params else {},\n",
    "        \"model_load_params\": model_load_params if model_load_params else {}\n",
    "    }\n",
    "\n",
    "    full_response_text = \"\"\n",
    "    print(f\"\\n[Session: {session_id}, Model: {model_id}] Asking: {user_prompt[:100]}...\")\n",
    "    if system_prompt:\n",
    "        print(f\"System Prompt: {system_prompt[:100]}...\")\n",
    "\n",
    "    try:\n",
    "        response = requests.post(f\"{api_base_url}/chat\", json=payload, stream=True, timeout=300) # Added timeout\n",
    "        response.raise_for_status()\n",
    "\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                decoded_line = line.decode('utf-8')\n",
    "                if decoded_line.startswith('data: '):\n",
    "                    try:\n",
    "                        data_json_str = decoded_line[len('data: '):]\n",
    "                        data_json = json.loads(data_json_str)\n",
    "                        \n",
    "                        if data_json.get('error'):\n",
    "                            error_msg = f\"[API Error for session {session_id}]: {data_json['error']}\"\n",
    "                            print(error_msg)\n",
    "                            return error_msg # Return error message as response\n",
    "\n",
    "                        if 'text_chunk' in data_json and not data_json.get('is_final'):\n",
    "                            full_response_text += data_json['text_chunk']\n",
    "                            # print(data_json['text_chunk'], end='', flush=True) # For live streaming in notebook\n",
    "                        \n",
    "                        if data_json.get('is_final'):\n",
    "                            if 'full_response' in data_json: # Use server's full response if available\n",
    "                                full_response_text = data_json['full_response']\n",
    "                            # print(\"\\n--- End of Stream ---\")\n",
    "                            break \n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"\\nWarning: Could not decode JSON from stream: {decoded_line}\")\n",
    "        \n",
    "        print(f\"[Session: {session_id}] Full Response: {full_response_text[:100]}...\")\n",
    "        return full_response_text.strip()\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        error_msg = f\"[API Timeout for session {session_id} while asking: {user_prompt[:50]}...]\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"[API Request Error for session {session_id}]: {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd453e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Worker Function to Process a Query Group\n",
    "def worker_process_query_group(query_group_config, model_id, api_base_url, all_results_list, results_lock):\n",
    "    \"\"\"\n",
    "    Worker function for a thread. Processes a group of questions.\n",
    "    Each query_group runs in its own session.\n",
    "    \"\"\"\n",
    "    group_id = query_group_config[\"group_id\"]\n",
    "    print(f\"Thread started for Query Group: {group_id}\")\n",
    "\n",
    "    session_id = create_new_session(api_base_url)\n",
    "    if not session_id:\n",
    "        print(f\"Failed to create session for group {group_id}. Aborting this group.\")\n",
    "        with results_lock:\n",
    "            all_results_list.append({\n",
    "                \"group_id\": group_id,\n",
    "                \"session_id\": None,\n",
    "                \"status\": \"failed_session_creation\",\n",
    "                \"results\": {}\n",
    "            })\n",
    "        return\n",
    "\n",
    "    system_prompt = query_group_config.get(\"system_prompt\", \"\")\n",
    "    generation_params = query_group_config.get(\"generation_params\", {})\n",
    "    model_load_params = query_group_config.get(\"model_load_params\", {})\n",
    "    default_temperature = query_group_config.get(\"temperature\", 0.7) # Can be set per group\n",
    "\n",
    "    group_results_data = {}\n",
    "\n",
    "    # The backend's /chat endpoint handles history accumulation based on session_id.\n",
    "    # We send the system_prompt with each call in this setup, \n",
    "    # or rely on the backend to use the first system_prompt for the session.\n",
    "    # The current backend app.py prepends the system_prompt if provided in the payload.\n",
    "    for q_item in query_group_config[\"questions_and_keys\"]:\n",
    "        user_question = q_item[\"question\"]\n",
    "        answer_key = q_item[\"key\"]\n",
    "        \n",
    "        answer = ask_question_on_session(\n",
    "            api_base_url, \n",
    "            model_id, \n",
    "            session_id, \n",
    "            user_question, \n",
    "            system_prompt, # System prompt is associated with the session by the backend\n",
    "            generation_params,\n",
    "            model_load_params,\n",
    "            temperature=default_temperature\n",
    "        )\n",
    "        group_results_data[answer_key] = answer\n",
    "        # time.sleep(1) # Optional: small delay between questions in the same session if needed\n",
    "\n",
    "    with results_lock:\n",
    "        all_results_list.append({\n",
    "            \"group_id\": group_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"status\": \"completed\",\n",
    "            \"results\": group_results_data\n",
    "        })\n",
    "    print(f\"Thread finished for Query Group: {group_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9000e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "license='''\n",
    "        California\n",
    "        DRIVER LICENSe\n",
    "        dl 11234568\n",
    "        CLASS C\n",
    "        EXP 08/31/2014\n",
    "        END NONE\n",
    "        LNCARDHOLDER FNIMA\n",
    "        2570 24TH STREET ANYTOWN, CA 95818\n",
    "        doB 08/31/1977 RSTR NONE\n",
    "        08311977\n",
    "        VETERAN\n",
    "        Cordhslde\n",
    "        SEX F HGT 5'-05\"\n",
    "        HAIR BRN WGT 125 lb\n",
    "        EYES BRN\n",
    "        DD 00/00/0000NNNAN/ANFD/YY\n",
    "        ISS 08/31/2009\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1179576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Model ID: gguf_local_Llama-3_2-1B-Instruct-Q8_0\n",
      "\n",
      "--- Processing Document: california_license_1 ---\n",
      "Created new session: fd26d80a-5148-4a3e-9e9b-5aa7e93b0cff\n",
      "\n",
      "[Session: fd26d80a-5148-4a3e-9e9b-5aa7e93b0cff, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What is the FULL address?\n",
      "\n",
      "License Text:\n",
      "\n",
      "        California\n",
      "        DRIVER LICENSe\n",
      "        dl 11234...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: fd26d80a-5148-4a3e-9e9b-5aa7e93b0cff] Full Response: \"2570 24TH STREET ANYTOWN, CA 95818\"...\n",
      "  Question 'What is the FULL address?...' processed in 3.26s\n",
      "\n",
      "[Session: fd26d80a-5148-4a3e-9e9b-5aa7e93b0cff, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What's the state?...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: fd26d80a-5148-4a3e-9e9b-5aa7e93b0cff] Full Response: California...\n",
      "  Question 'What's the state?...' processed in 2.41s\n",
      "\n",
      "[Session: fd26d80a-5148-4a3e-9e9b-5aa7e93b0cff, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What's the gender (SEX)?...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: fd26d80a-5148-4a3e-9e9b-5aa7e93b0cff] Full Response: F...\n",
      "  Question 'What's the gender (SEX)?...' processed in 2.38s\n",
      "\n",
      "[Session: fd26d80a-5148-4a3e-9e9b-5aa7e93b0cff, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What's the FULL NAME?...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: fd26d80a-5148-4a3e-9e9b-5aa7e93b0cff] Full Response: FNIMA...\n",
      "  Question 'What's the FULL NAME?...' processed in 3.65s\n",
      "--- Finished processing Document: california_license_1 in 13.74s ---\n",
      "\n",
      "--- All documents processed sequentially in 13.74 seconds ---\n",
      "\n",
      "--- Collected Results ---\n",
      "\n",
      "Document ID: california_license_1\n",
      "Session ID: fd26d80a-5148-4a3e-9e9b-5aa7e93b0cff\n",
      "Status: completed\n",
      "Processing Time for Doc: 13.74s\n",
      "  'full_address': \"2570 24TH STREET ANYTOWN, CA 95818\" (Returned as JSON)\n",
      "  'state': 'California' (Returned as Raw String, not the requested JSON format)\n",
      "  'gender': 'F' (Returned as Raw String, not the requested JSON format)\n",
      "  'full_name': 'FNIMA' (Returned as Raw String, not the requested JSON format)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main Execution Block (Single Session per License, License in First Prompt, Execution Time)\n",
    "\n",
    "# --- Configuration ---\n",
    "CHOSEN_MODEL_ID = \"gguf_local_Llama-3_2-1B-Instruct-Q8_0\" # <--- !!! SET YOUR MODEL ID HERE !!!\n",
    "\n",
    "# --- License Data ---\n",
    "license_text_1 = \"\"\"\n",
    "        California\n",
    "        DRIVER LICENSe\n",
    "        dl 11234568\n",
    "        CLASS C\n",
    "        EXP 08/31/2014\n",
    "        END NONE\n",
    "        LNCARDHOLDER FNIMA\n",
    "        2570 24TH STREET ANYTOWN, CA 95818\n",
    "        doB 08/31/1977 RSTR NONE\n",
    "        08311977\n",
    "        VETERAN\n",
    "        Cordhslde\n",
    "        SEX F HGT 5'-05\"\n",
    "        HAIR BRN WGT 125 lb\n",
    "        EYES BRN\n",
    "        DD 00/00/0000NNNAN/ANFD/YY\n",
    "        ISS 08/31/2009\n",
    "\"\"\"\n",
    "\n",
    "# --- Query Structure (Only one license document now) ---\n",
    "QUERY_DOCUMENTS = [\n",
    "    {\n",
    "        \"document_id\": \"california_license_1\",\n",
    "        \"license_text\": license_text_1,\n",
    "        \"system_prompt\": \"Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER.\",\n",
    "        \"questions_and_keys\": [\n",
    "            {\"question\": \"What is the FULL address?\", \"key\": \"full_address\", \"is_first_question\": True},\n",
    "            {\"question\": \"What's the state?\", \"key\": \"state\"},\n",
    "            {\"question\": \"What's the gender (SEX)?\", \"key\": \"gender\"},\n",
    "            {\"question\": \"What's the FULL NAME?\", \"key\": \"full_name\"},\n",
    "\n",
    "            # {\"question\": \"What is the Date of Birth (doB)?\", \"key\": \"date_of_birth\"},\n",
    "            # {\"question\": \"What is the License Expiry Date (EXP)?\", \"key\": \"expiry_date\"}\n",
    "        ],\n",
    "        \"temperature\": 0.01,\n",
    "        \"generation_params\": {\"max_tokens\": 150},\n",
    "        \"model_load_params\": {\"n_gpu_layers\": -1}\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Worker Function (Sequential Processing for a single document/license) ---\n",
    "def process_license_document_sequentially(document_config, model_id, api_base_url):\n",
    "    doc_id = document_config[\"document_id\"]\n",
    "    current_license_text = document_config[\"license_text\"]\n",
    "    system_prompt = document_config[\"system_prompt\"]\n",
    "    temperature = document_config.get(\"temperature\", 0.1)\n",
    "    generation_params = document_config.get(\"generation_params\", {})\n",
    "    model_load_params = document_config.get(\"model_load_params\", {})\n",
    "\n",
    "    doc_start_time = time.time() # Start timer for this document\n",
    "    print(f\"\\n--- Processing Document: {doc_id} ---\")\n",
    "\n",
    "    session_id = create_new_session(api_base_url)\n",
    "    if not session_id:\n",
    "        print(f\"Failed to create session for {doc_id}. Skipping this document.\")\n",
    "        return {\n",
    "            \"document_id\": doc_id,\n",
    "            \"session_id\": None,\n",
    "            \"status\": \"failed_session_creation\",\n",
    "            \"results\": {}\n",
    "        }\n",
    "\n",
    "    document_results_data = {}\n",
    "\n",
    "    for i, q_item in enumerate(document_config[\"questions_and_keys\"]):\n",
    "        question_start_time = time.time() # Start timer for this question\n",
    "        user_question_text = q_item[\"question\"]\n",
    "        answer_key = q_item[\"key\"]\n",
    "        \n",
    "        effective_user_prompt = \"\"\n",
    "        if q_item.get(\"is_first_question\", False):\n",
    "            effective_user_prompt = f\"{user_question_text}\\n\\nLicense Text:\\n{current_license_text}\"\n",
    "        else:\n",
    "            effective_user_prompt = user_question_text\n",
    "        \n",
    "        answer = ask_question_on_session(\n",
    "            api_base_url,\n",
    "            model_id,\n",
    "            session_id,\n",
    "            effective_user_prompt,\n",
    "            system_prompt,\n",
    "            generation_params,\n",
    "            model_load_params,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        document_results_data[answer_key] = answer\n",
    "        question_end_time = time.time()\n",
    "        print(f\"  Question '{user_question_text[:50]}...' processed in {question_end_time - question_start_time:.2f}s\")\n",
    "        # time.sleep(0.1) # Optional small delay\n",
    "\n",
    "    doc_end_time = time.time()\n",
    "    print(f\"--- Finished processing Document: {doc_id} in {doc_end_time - doc_start_time:.2f}s ---\")\n",
    "    return {\n",
    "        \"document_id\": doc_id,\n",
    "        \"session_id\": session_id,\n",
    "        \"status\": \"completed\",\n",
    "        \"results\": document_results_data,\n",
    "        \"processing_time_seconds\": doc_end_time - doc_start_time\n",
    "    }\n",
    "\n",
    "# --- Execution ---\n",
    "if 'AVAILABLE_MODELS' not in globals():\n",
    "    print(\"Warning: AVAILABLE_MODELS not found. Running Cell 2 to fetch models is recommended.\")\n",
    "    AVAILABLE_MODELS = []\n",
    "\n",
    "if CHOSEN_MODEL_ID == \"default_model_id_placeholder\" and not AVAILABLE_MODELS:\n",
    "    print(\"CRITICAL: CHOSEN_MODEL_ID is a placeholder, or AVAILABLE_MODELS is empty.\")\n",
    "    print(\"Please ensure your Flask server is running, Cell 2 ran successfully, and update CHOSEN_MODEL_ID if needed.\")\n",
    "else:\n",
    "    print(f\"Using Model ID: {CHOSEN_MODEL_ID}\")\n",
    "\n",
    "    all_collected_results = []\n",
    "    overall_start_time = time.time() # Start timer for the entire batch\n",
    "\n",
    "    for document_config in QUERY_DOCUMENTS:\n",
    "        result_item = process_license_document_sequentially(\n",
    "            document_config,\n",
    "            CHOSEN_MODEL_ID,\n",
    "            API_BASE_URL\n",
    "        )\n",
    "        all_collected_results.append(result_item)\n",
    "\n",
    "    overall_end_time = time.time()\n",
    "    total_processing_time = overall_end_time - overall_start_time\n",
    "    print(f\"\\n--- All documents processed sequentially in {total_processing_time:.2f} seconds ---\")\n",
    "\n",
    "    # --- Display Results ---\n",
    "    print(\"\\n--- Collected Results ---\")\n",
    "    for item in all_collected_results:\n",
    "        if item: \n",
    "            print(f\"\\nDocument ID: {item.get('document_id', 'N/A')}\")\n",
    "            print(f\"Session ID: {item.get('session_id', 'N/A')}\")\n",
    "            print(f\"Status: {item.get('status', 'N/A')}\")\n",
    "            if \"processing_time_seconds\" in item:\n",
    "                print(f\"Processing Time for Doc: {item['processing_time_seconds']:.2f}s\")\n",
    "\n",
    "# In Cell 6, within the \"--- Display Results ---\" section:\n",
    "\n",
    "            if item.get(\"results\"):\n",
    "                for key, value in item[\"results\"].items():\n",
    "                    is_valid_json_format = False\n",
    "                    parsed_json_value = None\n",
    "                    final_display_value = value # Default to raw value\n",
    "\n",
    "                    if isinstance(value, str): # Only attempt to parse if it's a string\n",
    "                        try:\n",
    "                            cleaned_value = value.strip()\n",
    "                            if cleaned_value.startswith(\"```json\"):\n",
    "                                cleaned_value = cleaned_value[len(\"```json\"):].strip()\n",
    "                            if cleaned_value.startswith(\"```\"):\n",
    "                                cleaned_value = cleaned_value[len(\"```\"):].strip()\n",
    "                            if cleaned_value.endswith(\"```\"):\n",
    "                                cleaned_value = cleaned_value[:-len(\"```\")].strip()\n",
    "                            \n",
    "                            # Now, try to parse the cleaned string as JSON\n",
    "                            parsed_json_value = json.loads(cleaned_value)\n",
    "                            \n",
    "                            # If the parsed value is a dictionary and contains our original key,\n",
    "                            # and the prompt asked for {\"key\": \"value\"}, we might want the inner value.\n",
    "                            # However, the prompt \"Example: {\\\"key\\\": \\\"value\\\"}\" implies the model should return\n",
    "                            # a dict where 'key' is actually the 'answer_key' from your config.\n",
    "                            # Example: if answer_key is \"full_name\", model should return {\"full_name\": \"FNIMA\"}\n",
    "                            \n",
    "                            # For now, let's assume the model is trying to return a JSON object\n",
    "                            # as per the system prompt's example.\n",
    "                            final_display_value = json.dumps(parsed_json_value) # Pretty print the whole JSON\n",
    "                            is_valid_json_format = True\n",
    "                        except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "                            # Value was a string but not valid JSON, or not a string at all\n",
    "                            final_display_value = value # Keep it raw\n",
    "                            is_valid_json_format = False\n",
    "                    \n",
    "                    # Print statement\n",
    "                    if is_valid_json_format:\n",
    "                        print(f\"  '{key}': {final_display_value} (Returned as JSON)\")\n",
    "                    else:\n",
    "                        print(f\"  '{key}': '{final_display_value}' (Returned as Raw String, not the requested JSON format)\")\n",
    "            else:\n",
    "                print(\"  No results for this document.\")\n",
    "        else:\n",
    "            print(\"\\nEncountered a None result item, skipping display for it.\")\n",
    "\n",
    "    # Save to JSON file\n",
    "    # results_filename = \"batch_license_extraction_single_session_timed.json\"\n",
    "    # with open(results_filename, \"w\") as f:\n",
    "    #     json.dump(all_collected_results, f, indent=2)\n",
    "    # print(f\"\\nResults saved to {results_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25de9468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Model ID: gguf_local_Llama-3_2-1B-Instruct-UD-Q8_K_XL\n",
      "\n",
      "--- Processing Document: california_license_1 ---\n",
      "Created new session: fe34dde0-30f4-491d-b354-a5923fb7dc72\n",
      "\n",
      "[Session: fe34dde0-30f4-491d-b354-a5923fb7dc72, Model: gguf_local_Llama-3_2-1B-Instruct-UD-Q8_K_XL] Asking: What is the FULL address?\n",
      "\n",
      "License Text:\n",
      "\n",
      "        California\n",
      "        DRIVER LICENSe\n",
      "        dl 11234...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: fe34dde0-30f4-491d-b354-a5923fb7dc72] Full Response: \"2570 24TH STREET ANYTOWN, CA 95818\"...\n",
      "  Question 'What is the FULL address?...' processed in 10.35s\n",
      "\n",
      "[Session: fe34dde0-30f4-491d-b354-a5923fb7dc72, Model: gguf_local_Llama-3_2-1B-Instruct-UD-Q8_K_XL] Asking: What's the state?...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: fe34dde0-30f4-491d-b354-a5923fb7dc72] Full Response: California...\n",
      "  Question 'What's the state?...' processed in 2.81s\n",
      "\n",
      "[Session: fe34dde0-30f4-491d-b354-a5923fb7dc72, Model: gguf_local_Llama-3_2-1B-Instruct-UD-Q8_K_XL] Asking: What's the gender (SEX)?...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: fe34dde0-30f4-491d-b354-a5923fb7dc72] Full Response: F...\n",
      "  Question 'What's the gender (SEX)?...' processed in 2.56s\n",
      "\n",
      "[Session: fe34dde0-30f4-491d-b354-a5923fb7dc72, Model: gguf_local_Llama-3_2-1B-Instruct-UD-Q8_K_XL] Asking: What's the FULL NAME?...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: fe34dde0-30f4-491d-b354-a5923fb7dc72] Full Response: FNIMA...\n",
      "  Question 'What's the FULL NAME?...' processed in 2.51s\n",
      "--- Finished processing Document: california_license_1 in 20.28s ---\n",
      "\n",
      "--- All documents processed sequentially in 20.28 seconds ---\n",
      "\n",
      "--- Collected Results ---\n",
      "\n",
      "Document ID: california_license_1\n",
      "Session ID: fe34dde0-30f4-491d-b354-a5923fb7dc72\n",
      "Status: completed\n",
      "Processing Time for Doc: 20.28s\n",
      "  'full_address': \"2570 24TH STREET ANYTOWN, CA 95818\" (Returned as JSON)\n",
      "  'state': 'California' (Returned as Raw String, not the requested JSON format)\n",
      "  'gender': 'F' (Returned as Raw String, not the requested JSON format)\n",
      "  'full_name': 'FNIMA' (Returned as Raw String, not the requested JSON format)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main Execution Block (Single Session per License, License in First Prompt, Execution Time)\n",
    "\n",
    "# --- Configuration ---\n",
    "CHOSEN_MODEL_ID = \"gguf_local_Llama-3_2-1B-Instruct-UD-Q8_K_XL\" # <--- !!! SET YOUR MODEL ID HERE !!!\n",
    "\n",
    "# --- License Data ---\n",
    "license_text_1 = \"\"\"\n",
    "        California\n",
    "        DRIVER LICENSe\n",
    "        dl 11234568\n",
    "        CLASS C\n",
    "        EXP 08/31/2014\n",
    "        END NONE\n",
    "        LNCARDHOLDER FNIMA\n",
    "        2570 24TH STREET ANYTOWN, CA 95818\n",
    "        doB 08/31/1977 RSTR NONE\n",
    "        08311977\n",
    "        VETERAN\n",
    "        Cordhslde\n",
    "        SEX F HGT 5'-05\"\n",
    "        HAIR BRN WGT 125 lb\n",
    "        EYES BRN\n",
    "        DD 00/00/0000NNNAN/ANFD/YY\n",
    "        ISS 08/31/2009\n",
    "\"\"\"\n",
    "\n",
    "# --- Query Structure (Only one license document now) ---\n",
    "QUERY_DOCUMENTS = [\n",
    "    {\n",
    "        \"document_id\": \"california_license_1\",\n",
    "        \"license_text\": license_text_1,\n",
    "        \"system_prompt\": \"Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER.\",\n",
    "        \"questions_and_keys\": [\n",
    "            {\"question\": \"What is the FULL address?\", \"key\": \"full_address\", \"is_first_question\": True},\n",
    "            {\"question\": \"What's the state?\", \"key\": \"state\"},\n",
    "            {\"question\": \"What's the gender (SEX)?\", \"key\": \"gender\"},\n",
    "            {\"question\": \"What's the FULL NAME?\", \"key\": \"full_name\"},\n",
    "\n",
    "            # {\"question\": \"What is the Date of Birth (doB)?\", \"key\": \"date_of_birth\"},\n",
    "            # {\"question\": \"What is the License Expiry Date (EXP)?\", \"key\": \"expiry_date\"}\n",
    "        ],\n",
    "        \"temperature\": 0.01,\n",
    "        \"generation_params\": {\"max_tokens\": 150},\n",
    "        \"model_load_params\": {\"n_gpu_layers\": -1}\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Worker Function (Sequential Processing for a single document/license) ---\n",
    "def process_license_document_sequentially(document_config, model_id, api_base_url):\n",
    "    doc_id = document_config[\"document_id\"]\n",
    "    current_license_text = document_config[\"license_text\"]\n",
    "    system_prompt = document_config[\"system_prompt\"]\n",
    "    temperature = document_config.get(\"temperature\", 0.1)\n",
    "    generation_params = document_config.get(\"generation_params\", {})\n",
    "    model_load_params = document_config.get(\"model_load_params\", {})\n",
    "\n",
    "    doc_start_time = time.time() # Start timer for this document\n",
    "    print(f\"\\n--- Processing Document: {doc_id} ---\")\n",
    "\n",
    "    session_id = create_new_session(api_base_url)\n",
    "    if not session_id:\n",
    "        print(f\"Failed to create session for {doc_id}. Skipping this document.\")\n",
    "        return {\n",
    "            \"document_id\": doc_id,\n",
    "            \"session_id\": None,\n",
    "            \"status\": \"failed_session_creation\",\n",
    "            \"results\": {}\n",
    "        }\n",
    "\n",
    "    document_results_data = {}\n",
    "\n",
    "    for i, q_item in enumerate(document_config[\"questions_and_keys\"]):\n",
    "        question_start_time = time.time() # Start timer for this question\n",
    "        user_question_text = q_item[\"question\"]\n",
    "        answer_key = q_item[\"key\"]\n",
    "        \n",
    "        effective_user_prompt = \"\"\n",
    "        if q_item.get(\"is_first_question\", False):\n",
    "            effective_user_prompt = f\"{user_question_text}\\n\\nLicense Text:\\n{current_license_text}\"\n",
    "        else:\n",
    "            effective_user_prompt = user_question_text\n",
    "        \n",
    "        answer = ask_question_on_session(\n",
    "            api_base_url,\n",
    "            model_id,\n",
    "            session_id,\n",
    "            effective_user_prompt,\n",
    "            system_prompt,\n",
    "            generation_params,\n",
    "            model_load_params,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        document_results_data[answer_key] = answer\n",
    "        question_end_time = time.time()\n",
    "        print(f\"  Question '{user_question_text[:50]}...' processed in {question_end_time - question_start_time:.2f}s\")\n",
    "        # time.sleep(0.1) # Optional small delay\n",
    "\n",
    "    doc_end_time = time.time()\n",
    "    print(f\"--- Finished processing Document: {doc_id} in {doc_end_time - doc_start_time:.2f}s ---\")\n",
    "    return {\n",
    "        \"document_id\": doc_id,\n",
    "        \"session_id\": session_id,\n",
    "        \"status\": \"completed\",\n",
    "        \"results\": document_results_data,\n",
    "        \"processing_time_seconds\": doc_end_time - doc_start_time\n",
    "    }\n",
    "\n",
    "# --- Execution ---\n",
    "if 'AVAILABLE_MODELS' not in globals():\n",
    "    print(\"Warning: AVAILABLE_MODELS not found. Running Cell 2 to fetch models is recommended.\")\n",
    "    AVAILABLE_MODELS = []\n",
    "\n",
    "if CHOSEN_MODEL_ID == \"default_model_id_placeholder\" and not AVAILABLE_MODELS:\n",
    "    print(\"CRITICAL: CHOSEN_MODEL_ID is a placeholder, or AVAILABLE_MODELS is empty.\")\n",
    "    print(\"Please ensure your Flask server is running, Cell 2 ran successfully, and update CHOSEN_MODEL_ID if needed.\")\n",
    "else:\n",
    "    print(f\"Using Model ID: {CHOSEN_MODEL_ID}\")\n",
    "\n",
    "    all_collected_results = []\n",
    "    overall_start_time = time.time() # Start timer for the entire batch\n",
    "\n",
    "    for document_config in QUERY_DOCUMENTS:\n",
    "        result_item = process_license_document_sequentially(\n",
    "            document_config,\n",
    "            CHOSEN_MODEL_ID,\n",
    "            API_BASE_URL\n",
    "        )\n",
    "        all_collected_results.append(result_item)\n",
    "\n",
    "    overall_end_time = time.time()\n",
    "    total_processing_time = overall_end_time - overall_start_time\n",
    "    print(f\"\\n--- All documents processed sequentially in {total_processing_time:.2f} seconds ---\")\n",
    "\n",
    "    # --- Display Results ---\n",
    "    print(\"\\n--- Collected Results ---\")\n",
    "    for item in all_collected_results:\n",
    "        if item: \n",
    "            print(f\"\\nDocument ID: {item.get('document_id', 'N/A')}\")\n",
    "            print(f\"Session ID: {item.get('session_id', 'N/A')}\")\n",
    "            print(f\"Status: {item.get('status', 'N/A')}\")\n",
    "            if \"processing_time_seconds\" in item:\n",
    "                print(f\"Processing Time for Doc: {item['processing_time_seconds']:.2f}s\")\n",
    "\n",
    "# In Cell 6, within the \"--- Display Results ---\" section:\n",
    "\n",
    "            if item.get(\"results\"):\n",
    "                for key, value in item[\"results\"].items():\n",
    "                    is_valid_json_format = False\n",
    "                    parsed_json_value = None\n",
    "                    final_display_value = value # Default to raw value\n",
    "\n",
    "                    if isinstance(value, str): # Only attempt to parse if it's a string\n",
    "                        try:\n",
    "                            cleaned_value = value.strip()\n",
    "                            if cleaned_value.startswith(\"```json\"):\n",
    "                                cleaned_value = cleaned_value[len(\"```json\"):].strip()\n",
    "                            if cleaned_value.startswith(\"```\"):\n",
    "                                cleaned_value = cleaned_value[len(\"```\"):].strip()\n",
    "                            if cleaned_value.endswith(\"```\"):\n",
    "                                cleaned_value = cleaned_value[:-len(\"```\")].strip()\n",
    "                            \n",
    "                            # Now, try to parse the cleaned string as JSON\n",
    "                            parsed_json_value = json.loads(cleaned_value)\n",
    "                            \n",
    "                            # If the parsed value is a dictionary and contains our original key,\n",
    "                            # and the prompt asked for {\"key\": \"value\"}, we might want the inner value.\n",
    "                            # However, the prompt \"Example: {\\\"key\\\": \\\"value\\\"}\" implies the model should return\n",
    "                            # a dict where 'key' is actually the 'answer_key' from your config.\n",
    "                            # Example: if answer_key is \"full_name\", model should return {\"full_name\": \"FNIMA\"}\n",
    "                            \n",
    "                            # For now, let's assume the model is trying to return a JSON object\n",
    "                            # as per the system prompt's example.\n",
    "                            final_display_value = json.dumps(parsed_json_value) # Pretty print the whole JSON\n",
    "                            is_valid_json_format = True\n",
    "                        except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "                            # Value was a string but not valid JSON, or not a string at all\n",
    "                            final_display_value = value # Keep it raw\n",
    "                            is_valid_json_format = False\n",
    "                    \n",
    "                    # Print statement\n",
    "                    if is_valid_json_format:\n",
    "                        print(f\"  '{key}': {final_display_value} (Returned as JSON)\")\n",
    "                    else:\n",
    "                        print(f\"  '{key}': '{final_display_value}' (Returned as Raw String, not the requested JSON format)\")\n",
    "            else:\n",
    "                print(\"  No results for this document.\")\n",
    "        else:\n",
    "            print(\"\\nEncountered a None result item, skipping display for it.\")\n",
    "\n",
    "    # Save to JSON file\n",
    "    # results_filename = \"batch_license_extraction_single_session_timed.json\"\n",
    "    # with open(results_filename, \"w\") as f:\n",
    "    #     json.dump(all_collected_results, f, indent=2)\n",
    "    # print(f\"\\nResults saved to {results_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2de8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "31011_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
