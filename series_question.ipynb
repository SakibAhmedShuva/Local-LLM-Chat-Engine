{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3014dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import requests\n",
    "import json\n",
    "import threading\n",
    "import uuid\n",
    "import time # For potential delays or timeouts if needed\n",
    "\n",
    "# Configuration for your Flask API\n",
    "API_BASE_URL = \"http://localhost:5000\" # Adjust if your API is on a different host/port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6109d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching models: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /models (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000173BE95F100>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Helper Function to Get Available Models\n",
    "def get_available_models(api_base_url):\n",
    "    \"\"\"Fetches the list of available models from the API.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{api_base_url}/models\")\n",
    "        response.raise_for_status()  # Raises an exception for HTTP errors\n",
    "        models = response.json()\n",
    "        print(\"Available Models:\")\n",
    "        for model in models:\n",
    "            print(f\"- ID: {model.get('id')}, Name: {model.get('name')}, Type: {model.get('type')}, Source: {model.get('source_type')}\")\n",
    "            if model.get('source_type') == 'local':\n",
    "                print(f\"  Path: {model.get('path')}\")\n",
    "            elif model.get('source_type') == 'hub':\n",
    "                if model.get('type') == 'gguf':\n",
    "                    print(f\"  Repo ID: {model.get('repo_id')}, Filename: {model.get('filename')}\")\n",
    "                else:\n",
    "                    print(f\"  Hub ID/Path: {model.get('path')}\")\n",
    "            # print(f\"  Default Params: {model.get('params')}\") # Uncomment for more detail\n",
    "        return models\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching models: {e}\")\n",
    "        return []\n",
    "\n",
    "# Fetch and display available models when this cell is run\n",
    "AVAILABLE_MODELS = get_available_models(API_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364ceba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Helper Function to Create a New Session\n",
    "def create_new_session(api_base_url):\n",
    "    \"\"\"Creates a new session via the API and returns the session_id.\"\"\"\n",
    "    try:\n",
    "        response = requests.post(f\"{api_base_url}/create-session\")\n",
    "        response.raise_for_status()\n",
    "        session_data = response.json()\n",
    "        if session_data.get('status') == 'success' and session_data.get('session_id'):\n",
    "            print(f\"Created new session: {session_data['session_id']}\")\n",
    "            return session_data['session_id']\n",
    "        else:\n",
    "            print(f\"Failed to create session: {session_data.get('message', 'Unknown error')}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error creating session: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c26371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Helper Function to Ask a Question on a Session (Handles SSE)\n",
    "def ask_question_on_session(api_base_url, model_id, session_id, user_prompt, system_prompt, \n",
    "                            generation_params=None, model_load_params=None, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Sends a question to the chat API for a given session and streams the response.\n",
    "    Returns the complete assistant response.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"session_id\": session_id,\n",
    "        \"prompt\": user_prompt,\n",
    "        \"system_prompt\": system_prompt,\n",
    "        \"model_id\": model_id,\n",
    "        \"temperature\": temperature,  # Base temperature\n",
    "        \"model_specific_params\": generation_params if generation_params else {},\n",
    "        \"model_load_params\": model_load_params if model_load_params else {}\n",
    "    }\n",
    "\n",
    "    full_response_text = \"\"\n",
    "    print(f\"\\n[Session: {session_id}, Model: {model_id}] Asking: {user_prompt[:100]}...\")\n",
    "    if system_prompt:\n",
    "        print(f\"System Prompt: {system_prompt[:100]}...\")\n",
    "\n",
    "    try:\n",
    "        response = requests.post(f\"{api_base_url}/chat\", json=payload, stream=True, timeout=300) # Added timeout\n",
    "        response.raise_for_status()\n",
    "\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                decoded_line = line.decode('utf-8')\n",
    "                if decoded_line.startswith('data: '):\n",
    "                    try:\n",
    "                        data_json_str = decoded_line[len('data: '):]\n",
    "                        data_json = json.loads(data_json_str)\n",
    "                        \n",
    "                        if data_json.get('error'):\n",
    "                            error_msg = f\"[API Error for session {session_id}]: {data_json['error']}\"\n",
    "                            print(error_msg)\n",
    "                            return error_msg # Return error message as response\n",
    "\n",
    "                        if 'text_chunk' in data_json and not data_json.get('is_final'):\n",
    "                            full_response_text += data_json['text_chunk']\n",
    "                            # print(data_json['text_chunk'], end='', flush=True) # For live streaming in notebook\n",
    "                        \n",
    "                        if data_json.get('is_final'):\n",
    "                            if 'full_response' in data_json: # Use server's full response if available\n",
    "                                full_response_text = data_json['full_response']\n",
    "                            # print(\"\\n--- End of Stream ---\")\n",
    "                            break \n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"\\nWarning: Could not decode JSON from stream: {decoded_line}\")\n",
    "        \n",
    "        print(f\"[Session: {session_id}] Full Response: {full_response_text[:100]}...\")\n",
    "        return full_response_text.strip()\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        error_msg = f\"[API Timeout for session {session_id} while asking: {user_prompt[:50]}...]\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"[API Request Error for session {session_id}]: {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd453e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Worker Function to Process a Query Group\n",
    "def worker_process_query_group(query_group_config, model_id, api_base_url, all_results_list, results_lock):\n",
    "    \"\"\"\n",
    "    Worker function for a thread. Processes a group of questions.\n",
    "    Each query_group runs in its own session.\n",
    "    \"\"\"\n",
    "    group_id = query_group_config[\"group_id\"]\n",
    "    print(f\"Thread started for Query Group: {group_id}\")\n",
    "\n",
    "    session_id = create_new_session(api_base_url)\n",
    "    if not session_id:\n",
    "        print(f\"Failed to create session for group {group_id}. Aborting this group.\")\n",
    "        with results_lock:\n",
    "            all_results_list.append({\n",
    "                \"group_id\": group_id,\n",
    "                \"session_id\": None,\n",
    "                \"status\": \"failed_session_creation\",\n",
    "                \"results\": {}\n",
    "            })\n",
    "        return\n",
    "\n",
    "    system_prompt = query_group_config.get(\"system_prompt\", \"\")\n",
    "    generation_params = query_group_config.get(\"generation_params\", {})\n",
    "    model_load_params = query_group_config.get(\"model_load_params\", {})\n",
    "    default_temperature = query_group_config.get(\"temperature\", 0.7) # Can be set per group\n",
    "\n",
    "    group_results_data = {}\n",
    "\n",
    "    # The backend's /chat endpoint handles history accumulation based on session_id.\n",
    "    # We send the system_prompt with each call in this setup, \n",
    "    # or rely on the backend to use the first system_prompt for the session.\n",
    "    # The current backend app.py prepends the system_prompt if provided in the payload.\n",
    "    for q_item in query_group_config[\"questions_and_keys\"]:\n",
    "        user_question = q_item[\"question\"]\n",
    "        answer_key = q_item[\"key\"]\n",
    "        \n",
    "        answer = ask_question_on_session(\n",
    "            api_base_url, \n",
    "            model_id, \n",
    "            session_id, \n",
    "            user_question, \n",
    "            system_prompt, # System prompt is associated with the session by the backend\n",
    "            generation_params,\n",
    "            model_load_params,\n",
    "            temperature=default_temperature\n",
    "        )\n",
    "        group_results_data[answer_key] = answer\n",
    "        # time.sleep(1) # Optional: small delay between questions in the same session if needed\n",
    "\n",
    "    with results_lock:\n",
    "        all_results_list.append({\n",
    "            \"group_id\": group_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"status\": \"completed\",\n",
    "            \"results\": group_results_data\n",
    "        })\n",
    "    print(f\"Thread finished for Query Group: {group_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9000e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "license='''\n",
    "        California\n",
    "        DRIVER LICENSe\n",
    "        dl 11234568\n",
    "        CLASS C\n",
    "        EXP 08/31/2014\n",
    "        END NONE\n",
    "        LNCARDHOLDER FNIMA\n",
    "        2570 24TH STREET ANYTOWN, CA 95818\n",
    "        doB 08/31/1977 RSTR NONE\n",
    "        08311977\n",
    "        VETERAN\n",
    "        Cordhslde\n",
    "        SEX F HGT 5'-05\"\n",
    "        HAIR BRN WGT 125 lb\n",
    "        EYES BRN\n",
    "        DD 00/00/0000NNNAN/ANFD/YY\n",
    "        ISS 08/31/2009\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 6: Main Execution Block\n",
    "\n",
    "# # --- Configuration ---\n",
    "# # Choose your model ID from the list printed by Cell 2\n",
    "# # Example: If you have a local GGUF model named \"mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n",
    "# # its ID might be \"gguf_local_mistral-7b-instruct-v0_2_Q4_K_M_gguf\"\n",
    "# # Or if you defined a Hub model in online_models.json with id \"zephyr-7b-gguf\"\n",
    "# CHOSEN_MODEL_ID = \"gguf_local_Llama-3_2-1B-Instruct-Q8_0\" # <--- !!! SET YOUR MODEL ID HERE !!!\n",
    "# # You can also get one from AVAILABLE_MODELS if it's not empty:\n",
    "# # if AVAILABLE_MODELS:\n",
    "# #    CHOSEN_MODEL_ID = AVAILABLE_MODELS[0]['id'] # Example: use the first available model\n",
    "# # else:\n",
    "# #    print(\"No models available from API. Please check server and config.\")\n",
    "# #    CHOSEN_MODEL_ID = \"default_model_id_placeholder\" # Fallback if no models listed\n",
    "\n",
    "# # Define your query groups\n",
    "# # Each item in QUERY_GROUPS will be processed in a separate thread, each with a new session.\n",
    "# # Questions within a \"questions_and_keys\" list for a single group are asked sequentially *within the same session*.\n",
    "# QUERY_GROUPS = [\n",
    "#     {\n",
    "#         \"group_id\": \"california_license_info_set1\",\n",
    "#         \"system_prompt\": (\n",
    "#             \"You are an expert AI assistant specializing in California driving licenses. \"\n",
    "#             \"Please answer the questions based on the following context. \"\n",
    "#             \"Context: The California Department of Motor Vehicles (DMV) states that the minimum age \"\n",
    "#             \"to apply for a learner's permit is 15 years and 6 months. Applicants for a REAL ID \"\n",
    "#             \"must provide proof of identity, their Social Security number (if eligible), and two \"\n",
    "#             \"proofs of California residency. The primary physical address for the CA DMV headquarters \"\n",
    "#             \"is in Sacramento, CA, USA. For a standard Class C license, vision screening is required.\"\n",
    "#         ),\n",
    "#         \"questions_and_keys\": [\n",
    "#             {\"question\": \"What is the minimum age to get a learner's permit in California?\", \"key\": \"ca_permit_min_age\"},\n",
    "#             {\"question\": \"List the categories of documents needed for a REAL ID application in California.\", \"key\": \"ca_realid_docs\"},\n",
    "#             {\"question\": \"What is the city and state of the CA DMV headquarters address?\", \"key\": \"ca_dmv_hq_address\"}\n",
    "#         ],\n",
    "#         \"temperature\": 0.01, # Override default temperature for this group\n",
    "#         \"generation_params\": {\"max_tokens\": 150}, # For GGUF: max_tokens; For HF: max_new_tokens\n",
    "#         \"model_load_params\": {\"n_gpu_layers\": -1} # Example for GGUF model\n",
    "#         # \"model_load_params\": {\"use_bnb_4bit\": True} # Example for Regular HF model if you want 4-bit\n",
    "#     },\n",
    "#     {\n",
    "#         \"group_id\": \"new_york_license_info_set1\",\n",
    "#         \"system_prompt\": (\n",
    "#             \"You are an expert AI assistant for New York State driving licenses. \"\n",
    "#             \"Context: Standard New York State driver licenses (Class D) are typically valid for 8 years. \"\n",
    "#             \"Renewals can often be done online, by mail, or in person at a DMV office. A vision test \"\n",
    "#             \"is required for renewal, which can be done at the DMV or by an approved provider.\"\n",
    "#         ),\n",
    "#         \"questions_and_keys\": [\n",
    "#             {\"question\": \"How long is a standard Class D driver's license valid in New York?\", \"key\": \"ny_license_validity\"},\n",
    "#             {\"question\": \"Is a vision test mandatory for renewing a NY driver's license?\", \"key\": \"ny_vision_test_renewal\"}\n",
    "#         ],\n",
    "#         \"temperature\": 0.01,\n",
    "#         \"generation_params\": {\"max_tokens\": 100},\n",
    "#         # model_load_params can be omitted if defaults are fine or model is already loaded with desired settings\n",
    "#     },\n",
    "#     {\n",
    "#         \"group_id\": \"california_license_info_set2_new_chat\", # Simulates new chat on existing topic\n",
    "#         \"system_prompt\": (\n",
    "#             \"You are an expert AI assistant specializing in California driving licenses. \"\n",
    "#             \"Please answer the questions based on the following context. \"\n",
    "#             \"Context: The California Driver Handbook outlines various traffic violations. A first-time \"\n",
    "#             \"DUI conviction can result in mandatory Ignition Interlock Device (IID) installation, \"\n",
    "#             \"license suspension, fines, and DUI program enrollment. The specific penalties can vary.\"\n",
    "#         ),\n",
    "#         \"questions_and_keys\": [\n",
    "#             {\"question\": \"What are some potential penalties for a first-time DUI in California according to the handbook?\", \"key\": \"ca_dui_penalties_first\"}\n",
    "#         ],\n",
    "#         \"generation_params\": {\"max_tokens\": 200},\n",
    "#         \"model_load_params\": {\"n_gpu_layers\": -1} \n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # --- Execution ---\n",
    "# if CHOSEN_MODEL_ID == \"default_model_id_placeholder\" and not AVAILABLE_MODELS:\n",
    "#     print(\"CRITICAL: CHOSEN_MODEL_ID is a placeholder and no models were fetched from the API.\")\n",
    "#     print(\"Please ensure your Flask server is running, configured with models, and update CHOSEN_MODEL_ID.\")\n",
    "# else:\n",
    "#     print(f\"Using Model ID: {CHOSEN_MODEL_ID}\")\n",
    "    \n",
    "#     collected_results = []\n",
    "#     threads = []\n",
    "#     results_lock = threading.Lock()\n",
    "\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     for group_config in QUERY_GROUPS:\n",
    "#         thread = threading.Thread(\n",
    "#             target=worker_process_query_group,\n",
    "#             args=(group_config, CHOSEN_MODEL_ID, API_BASE_URL, collected_results, results_lock)\n",
    "#         )\n",
    "#         threads.append(thread)\n",
    "#         thread.start()\n",
    "\n",
    "#     for thread in threads:\n",
    "#         thread.join() # Wait for all threads to complete\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     print(f\"\\n--- All threads completed in {end_time - start_time:.2f} seconds ---\")\n",
    "\n",
    "#     # --- Display Results ---\n",
    "#     print(\"\\n--- Collected Results ---\")\n",
    "#     for item in collected_results:\n",
    "#         print(f\"\\nQuery Group ID: {item['group_id']}\")\n",
    "#         print(f\"Session ID: {item['session_id']}\")\n",
    "#         print(f\"Status: {item.get('status', 'N/A')}\")\n",
    "#         if item.get(\"results\"):\n",
    "#             for key, value in item[\"results\"].items():\n",
    "#                 print(f\"  '{key}': '{value}'\")\n",
    "#         else:\n",
    "#             print(\"  No results for this group.\")\n",
    "            \n",
    "#     # You can also save `collected_results` to a JSON file\n",
    "#     # with open(\"batch_qa_results.json\", \"w\") as f:\n",
    "#     #     json.dump(collected_results, f, indent=2)\n",
    "#     # print(\"\\nResults saved to batch_qa_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b31bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Model ID: gguf_local_Llama-3_2-1B-Instruct-Q8_0\n",
      "Warning: API model list is empty. Assuming 'gguf_local_Llama-3_2-1B-Instruct-Q8_0' is GGUF for concurrency control.\n",
      "Applying GGUF concurrency limit: 1 concurrent requests.\n",
      "Thread for Doc: california_license_1_part1, Set: set1_address_sex: Waiting for semaphore...\n",
      "Thread for Doc: california_license_1_part1, Set: set1_address_sex: Semaphore acquired. Starting worker.\n",
      "Thread started for: Doc: california_license_1_part1, Set: set1_address_sex\n",
      "Thread for Doc: license_1_part2, Set: set2_name_weight: Waiting for semaphore...\n",
      "Created new session: 14987405-eb1d-41bc-a59e-a1fe39787692\n",
      "\n",
      "[Session: 14987405-eb1d-41bc-a59e-a1fe39787692, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What is the FULL ADDRESS?...\n",
      "System Prompt: You are an NER extraction expert. You will perfectly and accurately extract information from this dr...\n",
      "[Session: 14987405-eb1d-41bc-a59e-a1fe39787692] Full Response: \"2570 24TH STREET ANYTOWN, CA 95818\"...\n",
      "\n",
      "[Session: 14987405-eb1d-41bc-a59e-a1fe39787692, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What is the gender?...\n",
      "System Prompt: You are an NER extraction expert. You will perfectly and accurately extract information from this dr...\n",
      "[Session: 14987405-eb1d-41bc-a59e-a1fe39787692] Full Response: \"Male\"...\n",
      "Thread finished for: Doc: california_license_1_part1, Set: set1_address_sex\n",
      "Thread for Doc: california_license_1_part1, Set: set1_address_sex: Semaphore released.\n",
      "Thread for Doc: license_1_part2, Set: set2_name_weight: Semaphore acquired. Starting worker.\n",
      "Thread started for: Doc: license_1_part2, Set: set2_name_weight\n",
      "Created new session: 1576ab60-dc9b-41e8-b61b-0c8d530ce1fe\n",
      "\n",
      "[Session: 1576ab60-dc9b-41e8-b61b-0c8d530ce1fe, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What is the FULL NAME?...\n",
      "System Prompt: You are an NER extraction expert. You will perfectly and accurately extract information from this dr...\n",
      "[Session: 1576ab60-dc9b-41e8-b61b-0c8d530ce1fe] Full Response: \"FNIMA Cordhslde\"...\n",
      "\n",
      "[Session: 1576ab60-dc9b-41e8-b61b-0c8d530ce1fe, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What is the weight?...\n",
      "System Prompt: You are an NER extraction expert. You will perfectly and accurately extract information from this dr...\n",
      "[Session: 1576ab60-dc9b-41e8-b61b-0c8d530ce1fe] Full Response: \"62.5 kg\"...\n",
      "Thread finished for: Doc: license_1_part2, Set: set2_name_weight\n",
      "Thread for Doc: license_1_part2, Set: set2_name_weight: Semaphore released.\n",
      "\n",
      "--- All threads completed in 51.27 seconds ---\n",
      "\n",
      "--- Collected Results ---\n",
      "\n",
      "Document ID: california_license_1_part1, Set ID: set1_address_sex\n",
      "Session ID: 14987405-eb1d-41bc-a59e-a1fe39787692\n",
      "Status: completed\n",
      "  'full_address': \"2570 24TH STREET ANYTOWN, CA 95818\"\n",
      "  'sex': \"Male\"\n",
      "\n",
      "Document ID: license_1_part2, Set ID: set2_name_weight\n",
      "Session ID: 1576ab60-dc9b-41e8-b61b-0c8d530ce1fe\n",
      "Status: completed\n",
      "  'full_name': \"FNIMA Cordhslde\"\n",
      "  'weight': \"62.5 kg\"\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main Execution Block (Corrected for KeyError and License Text Usage)\n",
    "\n",
    "# --- Configuration ---\n",
    "CHOSEN_MODEL_ID = \"gguf_local_Llama-3_2-1B-Instruct-Q8_0\" # <--- !!! SET YOUR MODEL ID HERE !!!\n",
    "\n",
    "# --- License Data and Query Structure ---\n",
    "license_text_1 = '''\n",
    "        California\n",
    "        DRIVER LICENSe\n",
    "        dl 11234568\n",
    "        CLASS C\n",
    "        EXP 08/31/2014\n",
    "        END NONE\n",
    "        LNCARDHOLDER FNIMA\n",
    "        2570 24TH STREET ANYTOWN, CA 95818\n",
    "        doB 08/31/1977 RSTR NONE\n",
    "        08311977\n",
    "        VETERAN\n",
    "        Cordhslde\n",
    "        SEX F HGT 5'-05\"\n",
    "        HAIR BRN WGT 125 lb\n",
    "        EYES BRN\n",
    "        DD 00/00/0000NNNAN/ANFD/YY\n",
    "        ISS 08/31/2009\n",
    "'''\n",
    "\n",
    "# If license_text_2 was actually intended for a different license, define it here.\n",
    "# For now, per your comment, we'll assume the \"new_york_license_1\" document query\n",
    "# might be using license_text_1 but asking NY-style questions (or it was a placeholder).\n",
    "# If you have distinct text for license_text_2, replace `license_text_1` below with `license_text_2`.\n",
    "license_text_for_ny_example = license_text_1 # Change this if you have a separate NY license text\n",
    "\n",
    "\n",
    "# Define your query structure\n",
    "QUERY_DOCUMENTS = [\n",
    "    {\n",
    "        \"document_id\": \"california_license_1_part1\", # Changed ID to reflect it's part of the same license\n",
    "        \"license_text\": license_text_1, # Using the first part of the license\n",
    "        \"question_sets\": [\n",
    "            {\n",
    "                \"set_id\": \"set1_address_sex\",\n",
    "                # CORRECTED F-STRING: Double {{ and }} around JSON examples\n",
    "                \"system_prompt_q1_template\": \"You are an NER extraction expert. You will perfectly and accurately extract information from this driving license: {license_text_placeholder} Share answer a SINGLE WORD and JSON string ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE.\",\n",
    "                \"system_prompt_q_other_template\": \"You are an NER extraction expert. You will perfectly and accurately extract information from this driving license: {license_text_placeholder} Share answer a SINGLE WORD and JSON string ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE.\",\n",
    "                \"questions_and_keys\": [\n",
    "                    {\"question\": \"What is the FULL ADDRESS?\", \"key\": \"full_address\", \"is_first_question_in_set\": True},\n",
    "                    {\"question\": \"What is the gender?\", \"key\": \"sex\"}\n",
    "                ],\n",
    "                \"temperature\": 0.01,\n",
    "                \"generation_params\": {\"max_tokens\": 500},\n",
    "                \"model_load_params\": {\"n_gpu_layers\": -1}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"license_1_part2\", # Changed ID to reflect it's the second part of the SAME license\n",
    "        \"license_text\": license_text_1, # Using the same license text again (or a different part if you split it)\n",
    "        \"question_sets\": [\n",
    "             {\n",
    "                \"set_id\": \"set2_name_weight\", # This will be a NEW CHAT SESSION\n",
    "                 # CORRECTED F-STRING\n",
    "                 \"system_prompt_q1_template\": \"You are an NER extraction expert. You will perfectly and accurately extract information from this driving license: {license_text_placeholder} Share answer a SINGLE WORD and JSON string ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE.\",\n",
    "                 \"system_prompt_q_other_template\": \"You are an NER extraction expert. You will perfectly and accurately extract information from this driving license: {license_text_placeholder} Share answer a SINGLE WORD and JSON string ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE.\",\n",
    "                \"questions_and_keys\": [\n",
    "                    {\"question\": \"What is the FULL NAME?\", \"key\": \"full_name\", \"is_first_question_in_set\": True},\n",
    "                    {\"question\": \"What is the weight?\", \"key\": \"weight\"}\n",
    "                ],\n",
    "                \"temperature\": 0.01,\n",
    "                \"generation_params\": {\"max_tokens\": 80},\n",
    "                \"model_load_params\": {\"n_gpu_layers\": -1}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    # Example if you had a completely different license text for New York\n",
    "    # {\n",
    "    #     \"document_id\": \"new_york_license_actual_1\",\n",
    "    #     \"license_text\": license_text_for_ny_example, # This should be actual NY text if you have it\n",
    "    #     \"question_sets\": [\n",
    "    #         {\n",
    "    #             \"set_id\": \"ny_set1_id_expires_dob\",\n",
    "    #             # CORRECTED F-STRING\n",
    "    #             \"system_prompt_q1_template\": \"You are an expert in extracting specific fields from New York driver licenses. From this license: {license_text_placeholder} Provide the License ID in a SINGLE JSON string. Example: {{\\\"license_id\\\": \\\"123456789\\\"}}. No extra text.\",\n",
    "    #             \"system_prompt_q_other_template\": \"From the New York license previously discussed, provide the requested field in a SINGLE JSON string. Example: {{\\\"field\\\": \\\"value\\\"}}. No extra text.\",\n",
    "    #             \"questions_and_keys\": [\n",
    "    #                 {\"question\": \"What is the license ID number?\", \"key\": \"ny_license_id\", \"is_first_question_in_set\": True},\n",
    "    #                 {\"question\": \"When does the license expire?\", \"key\": \"ny_expires_date\"},\n",
    "    #                 {\"question\": \"What is the Date of Birth?\", \"key\": \"ny_dob\"}\n",
    "    #             ],\n",
    "    #             \"temperature\": 0.01,\n",
    "    #             \"generation_params\": {\"max_tokens\": 60},\n",
    "    #         }\n",
    "    #     ]\n",
    "    # }\n",
    "]\n",
    "\n",
    "# --- Modified Worker Function for Document and Question Sets ---\n",
    "def worker_process_document_question_set(document_config, question_set_config, model_id, api_base_url, all_results_list, results_lock):\n",
    "    doc_id = document_config[\"document_id\"]\n",
    "    set_id = question_set_config[\"set_id\"]\n",
    "    current_license_text = document_config[\"license_text\"]\n",
    "\n",
    "    thread_identifier = f\"Doc: {doc_id}, Set: {set_id}\"\n",
    "    print(f\"Thread started for: {thread_identifier}\")\n",
    "\n",
    "    session_id = create_new_session(api_base_url) # New session for each question_set\n",
    "    if not session_id:\n",
    "        print(f\"Failed to create session for {thread_identifier}. Aborting this set.\")\n",
    "        with results_lock:\n",
    "            all_results_list.append({\n",
    "                \"document_id\": doc_id,\n",
    "                \"set_id\": set_id,\n",
    "                \"session_id\": None,\n",
    "                \"status\": \"failed_session_creation\",\n",
    "                \"results\": {}\n",
    "            })\n",
    "        return\n",
    "\n",
    "    generation_params = question_set_config.get(\"generation_params\", {})\n",
    "    model_load_params = question_set_config.get(\"model_load_params\", {})\n",
    "    temperature = question_set_config.get(\"temperature\", 0.7)\n",
    "\n",
    "    set_results_data = {}\n",
    "\n",
    "    for i, q_item in enumerate(question_set_config[\"questions_and_keys\"]):\n",
    "        user_question = q_item[\"question\"]\n",
    "        answer_key = q_item[\"key\"]\n",
    "\n",
    "        if q_item.get(\"is_first_question_in_set\", False) and \"system_prompt_q1_template\" in question_set_config:\n",
    "            try:\n",
    "                system_prompt = question_set_config[\"system_prompt_q1_template\"].format(license_text_placeholder=current_license_text)\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError during system_prompt_q1_template formatting for {thread_identifier}: {e}\")\n",
    "                print(f\"Template string was: {question_set_config['system_prompt_q1_template']}\")\n",
    "                # Fallback or re-raise\n",
    "                system_prompt = \"Error in system prompt template. Please check.\"\n",
    "\n",
    "        elif \"system_prompt_q_other_template\" in question_set_config:\n",
    "            try:\n",
    "                system_prompt = question_set_config[\"system_prompt_q_other_template\"] # No placeholder here usually\n",
    "            except KeyError as e: # Should not happen if no placeholder\n",
    "                print(f\"KeyError during system_prompt_q_other_template formatting for {thread_identifier}: {e}\")\n",
    "                system_prompt = \"Error in system prompt template. Please check.\"\n",
    "        else:\n",
    "            system_prompt = f\"Regarding the license text: {current_license_text[:100]}...\"\n",
    "\n",
    "        effective_user_prompt = user_question\n",
    "\n",
    "        answer = ask_question_on_session(\n",
    "            api_base_url,\n",
    "            model_id,\n",
    "            session_id,\n",
    "            effective_user_prompt,\n",
    "            system_prompt,\n",
    "            generation_params,\n",
    "            model_load_params,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        set_results_data[answer_key] = answer\n",
    "\n",
    "    with results_lock:\n",
    "        all_results_list.append({\n",
    "            \"document_id\": doc_id,\n",
    "            \"set_id\": set_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"status\": \"completed\",\n",
    "            \"results\": set_results_data\n",
    "        })\n",
    "    print(f\"Thread finished for: {thread_identifier}\")\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "if 'AVAILABLE_MODELS' not in globals():\n",
    "    print(\"Warning: AVAILABLE_MODELS not found. Running Cell 2 to fetch models is recommended.\")\n",
    "    AVAILABLE_MODELS = []\n",
    "\n",
    "if CHOSEN_MODEL_ID == \"default_model_id_placeholder\" and not AVAILABLE_MODELS:\n",
    "    print(\"CRITICAL: CHOSEN_MODEL_ID is a placeholder, or AVAILABLE_MODELS is empty.\")\n",
    "    print(\"Please ensure your Flask server is running, Cell 2 ran successfully, and update CHOSEN_MODEL_ID if needed.\")\n",
    "else:\n",
    "    print(f\"Using Model ID: {CHOSEN_MODEL_ID}\")\n",
    "\n",
    "    collected_results = []\n",
    "    threads = []\n",
    "    results_lock = threading.Lock()\n",
    "\n",
    "    is_gguf_model = False\n",
    "    if AVAILABLE_MODELS:\n",
    "        model_meta = next((m for m in AVAILABLE_MODELS if m.get('id') == CHOSEN_MODEL_ID), None)\n",
    "        if model_meta and model_meta.get('type') == 'gguf':\n",
    "            is_gguf_model = True\n",
    "            print(f\"Model '{CHOSEN_MODEL_ID}' identified as GGUF type from API model list.\")\n",
    "    elif not AVAILABLE_MODELS and \"gguf\" in CHOSEN_MODEL_ID.lower():\n",
    "        is_gguf_model = True\n",
    "        print(f\"Warning: API model list is empty. Assuming '{CHOSEN_MODEL_ID}' is GGUF for concurrency control.\")\n",
    "\n",
    "    if is_gguf_model:\n",
    "        MAX_CONCURRENT_REQUESTS = 1\n",
    "        print(f\"Applying GGUF concurrency limit: {MAX_CONCURRENT_REQUESTS} concurrent requests.\")\n",
    "    else:\n",
    "        MAX_CONCURRENT_REQUESTS = min(sum(len(doc[\"question_sets\"]) for doc in QUERY_DOCUMENTS), 3)\n",
    "        print(f\"Applying default/non-GGUF concurrency limit: {MAX_CONCURRENT_REQUESTS} concurrent requests.\")\n",
    "\n",
    "    request_semaphore = threading.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "\n",
    "    def semaphore_worker_wrapper(worker_func, *args_for_worker):\n",
    "        doc_id_log = args_for_worker[0].get(\"document_id\", \"UnknownDoc\")\n",
    "        set_id_log = args_for_worker[1].get(\"set_id\", \"UnknownSet\")\n",
    "        thread_log_id = f\"Doc: {doc_id_log}, Set: {set_id_log}\"\n",
    "\n",
    "        print(f\"Thread for {thread_log_id}: Waiting for semaphore...\")\n",
    "        acquired = request_semaphore.acquire()\n",
    "        if acquired:\n",
    "            print(f\"Thread for {thread_log_id}: Semaphore acquired. Starting worker.\")\n",
    "            try:\n",
    "                worker_func(*args_for_worker)\n",
    "            finally:\n",
    "                request_semaphore.release()\n",
    "                print(f\"Thread for {thread_log_id}: Semaphore released.\")\n",
    "        else:\n",
    "            print(f\"Thread for {thread_log_id}: Failed to acquire semaphore (unexpected).\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for document_config in QUERY_DOCUMENTS:\n",
    "        for question_set_config in document_config[\"question_sets\"]:\n",
    "            thread = threading.Thread(\n",
    "                target=semaphore_worker_wrapper,\n",
    "                args=(\n",
    "                    worker_process_document_question_set,\n",
    "                    document_config,\n",
    "                    question_set_config,\n",
    "                    CHOSEN_MODEL_ID,\n",
    "                    API_BASE_URL,\n",
    "                    collected_results,\n",
    "                    results_lock\n",
    "                )\n",
    "            )\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n--- All threads completed in {end_time - start_time:.2f} seconds ---\")\n",
    "\n",
    "    print(\"\\n--- Collected Results ---\")\n",
    "    for item in collected_results:\n",
    "        print(f\"\\nDocument ID: {item['document_id']}, Set ID: {item['set_id']}\")\n",
    "        print(f\"Session ID: {item['session_id']}\")\n",
    "        print(f\"Status: {item.get('status', 'N/A')}\")\n",
    "        if item.get(\"results\"):\n",
    "            for key, value in item[\"results\"].items():\n",
    "                # Attempt to parse JSON if value looks like it, otherwise print as string\n",
    "                try:\n",
    "                    parsed_value = json.loads(value)\n",
    "                    print(f\"  '{key}': {json.dumps(parsed_value)}\") # Print parsed JSON neatly\n",
    "                except (json.JSONDecodeError, TypeError):\n",
    "                    print(f\"  '{key}': '{value}'\") # Print as raw string if not valid JSON\n",
    "        else:\n",
    "            print(\"  No results for this group.\")\n",
    "\n",
    "    # with open(\"batch_license_extraction_results_corrected.json\", \"w\") as f:\n",
    "    #     json.dump(collected_results, f, indent=2)\n",
    "    # print(\"\\nResults saved to batch_license_extraction_results_corrected.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1179576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Model ID: gguf_local_Llama-3_2-1B-Instruct-Q8_0\n",
      "\n",
      "--- Processing Document: california_license_1 ---\n",
      "Created new session: 81030040-de1d-42ea-a8d2-213dd9a0f86e\n",
      "\n",
      "[Session: 81030040-de1d-42ea-a8d2-213dd9a0f86e, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What is the FULL address?\n",
      "\n",
      "License Text:\n",
      "\n",
      "        California\n",
      "        DRIVER LICENSe\n",
      "        dl 11234...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: 81030040-de1d-42ea-a8d2-213dd9a0f86e] Full Response: \"2570 24TH STREET ANYTOWN, CA 95818\"...\n",
      "  Question 'What is the FULL address?...' processed in 12.43s\n",
      "\n",
      "[Session: 81030040-de1d-42ea-a8d2-213dd9a0f86e, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What's the FULL NAME (LNCARDHOLDER)?...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: 81030040-de1d-42ea-a8d2-213dd9a0f86e] Full Response: FNIMA...\n",
      "  Question 'What's the FULL NAME (LNCARDHOLDER)?...' processed in 2.57s\n",
      "\n",
      "[Session: 81030040-de1d-42ea-a8d2-213dd9a0f86e, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What's the gender (SEX)?...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: 81030040-de1d-42ea-a8d2-213dd9a0f86e] Full Response: F...\n",
      "  Question 'What's the gender (SEX)?...' processed in 2.48s\n",
      "\n",
      "[Session: 81030040-de1d-42ea-a8d2-213dd9a0f86e, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What is the Date of Birth (doB)?...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: 81030040-de1d-42ea-a8d2-213dd9a0f86e] Full Response: 08/31/1977...\n",
      "  Question 'What is the Date of Birth (doB)?...' processed in 2.85s\n",
      "\n",
      "[Session: 81030040-de1d-42ea-a8d2-213dd9a0f86e, Model: gguf_local_Llama-3_2-1B-Instruct-Q8_0] Asking: What is the License Expiry Date (EXP)?...\n",
      "System Prompt: Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER....\n",
      "[Session: 81030040-de1d-42ea-a8d2-213dd9a0f86e] Full Response: 08/31/2024...\n",
      "  Question 'What is the License Expiry Date (EXP)?...' processed in 2.88s\n",
      "--- Finished processing Document: california_license_1 in 25.27s ---\n",
      "\n",
      "--- All documents processed sequentially in 25.27 seconds ---\n",
      "\n",
      "--- Collected Results ---\n",
      "\n",
      "Document ID: california_license_1\n",
      "Session ID: 81030040-de1d-42ea-a8d2-213dd9a0f86e\n",
      "Status: completed\n",
      "Processing Time for Doc: 25.27s\n",
      "  'full_address': \"2570 24TH STREET ANYTOWN, CA 95818\"\n",
      "  'full_name': 'FNIMA' (Raw or parsing error)\n",
      "  'gender': 'F' (Raw or parsing error)\n",
      "  'date_of_birth': '08/31/1977' (Raw or parsing error)\n",
      "  'expiry_date': '08/31/2024' (Raw or parsing error)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main Execution Block (Single Session per License, License in First Prompt, Execution Time)\n",
    "\n",
    "# --- Configuration ---\n",
    "CHOSEN_MODEL_ID = \"gguf_local_Llama-3_2-1B-Instruct-Q8_0\" # <--- !!! SET YOUR MODEL ID HERE !!!\n",
    "\n",
    "# --- License Data ---\n",
    "license_text_1 = \"\"\"\n",
    "        California\n",
    "        DRIVER LICENSe\n",
    "        dl 11234568\n",
    "        CLASS C\n",
    "        EXP 08/31/2014\n",
    "        END NONE\n",
    "        LNCARDHOLDER FNIMA\n",
    "        2570 24TH STREET ANYTOWN, CA 95818\n",
    "        doB 08/31/1977 RSTR NONE\n",
    "        08311977\n",
    "        VETERAN\n",
    "        Cordhslde\n",
    "        SEX F HGT 5'-05\"\n",
    "        HAIR BRN WGT 125 lb\n",
    "        EYES BRN\n",
    "        DD 00/00/0000NNNAN/ANFD/YY\n",
    "        ISS 08/31/2009\n",
    "\"\"\"\n",
    "\n",
    "# --- Query Structure (Only one license document now) ---\n",
    "QUERY_DOCUMENTS = [\n",
    "    {\n",
    "        \"document_id\": \"california_license_1\",\n",
    "        \"license_text\": license_text_1,\n",
    "        \"system_prompt\": \"Share answer in a single word in JSON ONLY. DON'T ADD ANY OTHER WORD/REMARK/NOTE WITH THE ANSWER.\",\n",
    "        \"questions_and_keys\": [\n",
    "            {\"question\": \"What is the FULL address?\", \"key\": \"full_address\", \"is_first_question\": True},\n",
    "            {\"question\": \"What's the FULL NAME (LNCARDHOLDER)?\", \"key\": \"full_name\"},\n",
    "            {\"question\": \"What's the gender (SEX)?\", \"key\": \"gender\"},\n",
    "            {\"question\": \"What is the Date of Birth (doB)?\", \"key\": \"date_of_birth\"},\n",
    "            {\"question\": \"What is the License Expiry Date (EXP)?\", \"key\": \"expiry_date\"}\n",
    "        ],\n",
    "        \"temperature\": 0.01,\n",
    "        \"generation_params\": {\"max_tokens\": 150},\n",
    "        \"model_load_params\": {\"n_gpu_layers\": -1}\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Worker Function (Sequential Processing for a single document/license) ---\n",
    "def process_license_document_sequentially(document_config, model_id, api_base_url):\n",
    "    doc_id = document_config[\"document_id\"]\n",
    "    current_license_text = document_config[\"license_text\"]\n",
    "    system_prompt = document_config[\"system_prompt\"]\n",
    "    temperature = document_config.get(\"temperature\", 0.1)\n",
    "    generation_params = document_config.get(\"generation_params\", {})\n",
    "    model_load_params = document_config.get(\"model_load_params\", {})\n",
    "\n",
    "    doc_start_time = time.time() # Start timer for this document\n",
    "    print(f\"\\n--- Processing Document: {doc_id} ---\")\n",
    "\n",
    "    session_id = create_new_session(api_base_url)\n",
    "    if not session_id:\n",
    "        print(f\"Failed to create session for {doc_id}. Skipping this document.\")\n",
    "        return {\n",
    "            \"document_id\": doc_id,\n",
    "            \"session_id\": None,\n",
    "            \"status\": \"failed_session_creation\",\n",
    "            \"results\": {}\n",
    "        }\n",
    "\n",
    "    document_results_data = {}\n",
    "\n",
    "    for i, q_item in enumerate(document_config[\"questions_and_keys\"]):\n",
    "        question_start_time = time.time() # Start timer for this question\n",
    "        user_question_text = q_item[\"question\"]\n",
    "        answer_key = q_item[\"key\"]\n",
    "        \n",
    "        effective_user_prompt = \"\"\n",
    "        if q_item.get(\"is_first_question\", False):\n",
    "            effective_user_prompt = f\"{user_question_text}\\n\\nLicense Text:\\n{current_license_text}\"\n",
    "        else:\n",
    "            effective_user_prompt = user_question_text\n",
    "        \n",
    "        answer = ask_question_on_session(\n",
    "            api_base_url,\n",
    "            model_id,\n",
    "            session_id,\n",
    "            effective_user_prompt,\n",
    "            system_prompt,\n",
    "            generation_params,\n",
    "            model_load_params,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        document_results_data[answer_key] = answer\n",
    "        question_end_time = time.time()\n",
    "        print(f\"  Question '{user_question_text[:50]}...' processed in {question_end_time - question_start_time:.2f}s\")\n",
    "        # time.sleep(0.1) # Optional small delay\n",
    "\n",
    "    doc_end_time = time.time()\n",
    "    print(f\"--- Finished processing Document: {doc_id} in {doc_end_time - doc_start_time:.2f}s ---\")\n",
    "    return {\n",
    "        \"document_id\": doc_id,\n",
    "        \"session_id\": session_id,\n",
    "        \"status\": \"completed\",\n",
    "        \"results\": document_results_data,\n",
    "        \"processing_time_seconds\": doc_end_time - doc_start_time\n",
    "    }\n",
    "\n",
    "# --- Execution ---\n",
    "if 'AVAILABLE_MODELS' not in globals():\n",
    "    print(\"Warning: AVAILABLE_MODELS not found. Running Cell 2 to fetch models is recommended.\")\n",
    "    AVAILABLE_MODELS = []\n",
    "\n",
    "if CHOSEN_MODEL_ID == \"default_model_id_placeholder\" and not AVAILABLE_MODELS:\n",
    "    print(\"CRITICAL: CHOSEN_MODEL_ID is a placeholder, or AVAILABLE_MODELS is empty.\")\n",
    "    print(\"Please ensure your Flask server is running, Cell 2 ran successfully, and update CHOSEN_MODEL_ID if needed.\")\n",
    "else:\n",
    "    print(f\"Using Model ID: {CHOSEN_MODEL_ID}\")\n",
    "\n",
    "    all_collected_results = []\n",
    "    overall_start_time = time.time() # Start timer for the entire batch\n",
    "\n",
    "    for document_config in QUERY_DOCUMENTS:\n",
    "        result_item = process_license_document_sequentially(\n",
    "            document_config,\n",
    "            CHOSEN_MODEL_ID,\n",
    "            API_BASE_URL\n",
    "        )\n",
    "        all_collected_results.append(result_item)\n",
    "\n",
    "    overall_end_time = time.time()\n",
    "    total_processing_time = overall_end_time - overall_start_time\n",
    "    print(f\"\\n--- All documents processed sequentially in {total_processing_time:.2f} seconds ---\")\n",
    "\n",
    "    # --- Display Results ---\n",
    "    print(\"\\n--- Collected Results ---\")\n",
    "    for item in all_collected_results:\n",
    "        if item: \n",
    "            print(f\"\\nDocument ID: {item.get('document_id', 'N/A')}\")\n",
    "            print(f\"Session ID: {item.get('session_id', 'N/A')}\")\n",
    "            print(f\"Status: {item.get('status', 'N/A')}\")\n",
    "            if \"processing_time_seconds\" in item:\n",
    "                print(f\"Processing Time for Doc: {item['processing_time_seconds']:.2f}s\")\n",
    "\n",
    "            if item.get(\"results\"):\n",
    "                for key, value in item[\"results\"].items():\n",
    "                    try:\n",
    "                        cleaned_value = value.strip()\n",
    "                        if cleaned_value.startswith(\"```json\"):\n",
    "                            cleaned_value = cleaned_value[len(\"```json\"):].strip()\n",
    "                        if cleaned_value.startswith(\"```\"):\n",
    "                            cleaned_value = cleaned_value[len(\"```\"):].strip()\n",
    "                        if cleaned_value.endswith(\"```\"):\n",
    "                            cleaned_value = cleaned_value[:-len(\"```\")].strip()\n",
    "                        \n",
    "                        parsed_value = json.loads(cleaned_value)\n",
    "                        print(f\"  '{key}': {json.dumps(parsed_value)}\") \n",
    "                    except (json.JSONDecodeError, TypeError, AttributeError): # Added AttributeError for .strip() on non-string\n",
    "                        print(f\"  '{key}': '{value}' (Raw or parsing error)\")\n",
    "            else:\n",
    "                print(\"  No results for this document.\")\n",
    "        else:\n",
    "            print(\"\\nEncountered a None result item, skipping display for it.\")\n",
    "\n",
    "    # Save to JSON file\n",
    "    # results_filename = \"batch_license_extraction_single_session_timed.json\"\n",
    "    # with open(results_filename, \"w\") as f:\n",
    "    #     json.dump(all_collected_results, f, indent=2)\n",
    "    # print(f\"\\nResults saved to {results_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de9468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "31011_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
